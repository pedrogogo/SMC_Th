{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import csv\n",
    "\n",
    "#un-comment line below to print whole numpy arrays (note that computing cost will be much higher)\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "#this opens_loads the json files and assign them to their corresponding variables\n",
    "\n",
    "dict_bright = json.load(open(\"json_files/bright_analysis.json\", 'rb'))\n",
    "dict_metal = json.load(open(\"json_files/metal_analysis.json\",'rb'))\n",
    "dict_hard = json.load(open(\"json_files/hard_analysis.json\",'rb'))\n",
    "dict_reverb = json.load(open(\"json_files/reverb_analysis.json\",'rb'))\n",
    "dict_rough = json.load(open(\"json_files/rough_analysis.json\",'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dict_bright #printing to see comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing CSV files \n",
    "\n",
    "with open('csv_files/bright.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    bright_list_csv = list(reader)\n",
    "    #removing brackets from list\n",
    "    bright_list = [l[0] for l in bright_list_csv]\n",
    "    \n",
    "with open('csv_files/warm.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    warm_list_csv = list(reader)\n",
    "    warm_list = [l[0] for l in warm_list_csv]\n",
    "    \n",
    "with open('csv_files/rough.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    rough_list_csv = map(tuple, reader)\n",
    "    rough_list = [l[0] for l in rough_list_csv]\n",
    "    \n",
    "with open('csv_files/reverb.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    reverb_list_csv = map(tuple, reader)\n",
    "    reverb_list = [l[0] for l in reverb_list_csv]\n",
    "    \n",
    "with open('csv_files/clear.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    clear_list_csv = list(reader)\n",
    "    clear_list = [l[0] for l in clear_list_csv]\n",
    "    \n",
    "with open('csv_files/hollow.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    hollow_list_csv = list(reader)\n",
    "    hollow_list = [l[0] for l in hollow_list_csv]\n",
    "    \n",
    "with open('csv_files/deep.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    deep_list_csv = list(reader)\n",
    "    deep_list = [l[0] for l in deep_list_csv]\n",
    "    \n",
    "with open('csv_files/punchy.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    punchy_list_csv = list(reader)\n",
    "    punchy_list = [l[0] for l in punchy_list_csv]\n",
    "    \n",
    "with open('csv_files/metallic.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    metallic_list_csv = list(reader)\n",
    "    metallic_list = [l[0] for l in metallic_list_csv]\n",
    "    \n",
    "with open('csv_files/sharp.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sharp_list_csv = list(reader)\n",
    "    sharp_list = [l[0] for l in sharp_list_csv]\n",
    "    \n",
    "with open('csv_files/hard.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    hard_list_csv = list(reader) \n",
    "    hard_list = [l[0] for l in hard_list_csv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hard_list #print if want to see content.change accordingly for other lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#El número de sonidos en tu dataset:\n",
    "nb_sounds = len(set(bright_list + hard_list +warm_list + rough_list + reverb_list + clear_list + hollow_list + deep_list + punchy_list + metallic_list + sharp_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sounds_list = (set(bright_list + hard_list +warm_list + rough_list + reverb_list + clear_list + hollow_list + deep_list + punchy_list + metallic_list + sharp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"sounds_list.txt\", \"w\") as output:\n",
    "    output.write(str(sounds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bright length: 2745\n",
      "metal length: 2645\n",
      "hard length: 2735\n",
      "reverb length: 2422\n",
      "rough length: 2736\n"
     ]
    }
   ],
   "source": [
    "print \"bright length:\",len(dict_bright)\n",
    "print \"metal length:\",len(dict_metal)\n",
    "print \"hard length:\",len(dict_hard)\n",
    "print \"reverb length:\",len(dict_reverb)\n",
    "print \"rough length:\",len(dict_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning_removing \"nan\" values from the dicts\n",
    "clean_dict_bright = filter(lambda k: not np.isnan(dict_bright[k]), dict_bright)\n",
    "clean_dict_metal = filter(lambda k: not np.isnan(dict_metal[k]), dict_metal)\n",
    "clean_dict_hard = filter(lambda k: not np.isnan(dict_hard[k]), dict_hard)\n",
    "clean_dict_reverb = filter(lambda k: not np.isnan(dict_reverb[k]), dict_reverb)\n",
    "clean_dict_rough = filter(lambda k: not np.isnan(dict_rough[k]), dict_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bright length: 2745\n",
      "metal length: 2562\n",
      "hard length: 2721\n",
      "reverb length: 2422\n",
      "rough length: 2736\n"
     ]
    }
   ],
   "source": [
    "print \"bright length:\",len(clean_dict_bright)\n",
    "print \"metal length:\",len(clean_dict_metal)\n",
    "print \"hard length:\",len(clean_dict_hard)\n",
    "print \"reverb length:\",len(clean_dict_reverb)\n",
    "print \"rough length:\",len(clean_dict_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean_dict_bright #checking out one of them to see content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying intersection to all the lists\n",
    "all_ids_intersection=list(set(clean_dict_bright) & set(clean_dict_metal) & set(clean_dict_hard) & set(clean_dict_rough))\n",
    "all_ids_intersection\n",
    "len(all_ids_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating matrix X\n",
    "X = []\n",
    "\n",
    "for fs_id in all_ids_intersection:\n",
    "    #print fs_id\n",
    "    feature_vector = [dict_bright[fs_id], dict_metal[fs_id], dict_hard[fs_id],dict_rough[fs_id]]\n",
    "    X.append(feature_vector)\n",
    "len(feature_vector)    \n",
    "X = np.array(X)    \n",
    "#X  #printing out matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550\n"
     ]
    }
   ],
   "source": [
    "#confirming it matches in size as supposed to.\n",
    "print len(all_ids_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "NB_SOUNDS = len(X)  #here will get same result if using \"all_ids_intersection\" instead of \"X\"\n",
    "NB_LABELS = len(feature_vector)\n",
    "\n",
    "y = np.zeros((NB_SOUNDS, NB_LABELS), dtype=int)\n",
    "\n",
    "for idx, sound_id in enumerate(all_ids_intersection): # recorro todos los sonidos (lineas)\n",
    "    if sound_id in bright_list: # si el sonido es bright\n",
    "        y[idx][0] = 1 # add a 1 for each line (soundid) \"idx\" and the columns (label) 0....\n",
    "    if sound_id in metallic_list: \n",
    "        y[idx][1] = 1 # add a 1 for each line (soundid) \"idx\" and the columns (label) 1....\n",
    "    if sound_id in hard_list: \n",
    "        y[idx][2] = 1 # add a 1 for each line (soundid) \"idx\" and the columns (label) 2....\n",
    "    if sound_id in rough_list: \n",
    "        y[idx][3] = 1 # add a 1 for each line (soundid) \"idx\" and the columns (label) 3....´\n",
    "\n",
    "        \n",
    "#Y = np.array(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y  #printing out y matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((510, 4), (510, 4))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train  #cheking X_train matrix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN\n",
    "clf = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76313725490196083"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68449197860962563, 0.68469416227912205, 0.68449197860962563)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The recall is the ratio tp / (tp + fn) \n",
    "#where tp is the number of true positives and fn the number of false negatives.\n",
    "#The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "x1 = recall_score(y_true, y_pred, average='micro') \n",
    "x2 = recall_score(y_true, y_pred, average='macro') \n",
    "x3 = recall_score(y_true, y_pred, average='weighted')\n",
    "x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98841698841698844, 0.98584905660377364, 0.98713550600343059)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The precision is the ratio tp / (tp + fp) \n",
    "#where tp is the number of true positives and fp the number of false positives. \n",
    "#The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "macro_prec=precision_score(y_true, y_pred, average='macro') \n",
    "weigh_prec= precision_score(y_true, y_pred, average='weighted')\n",
    "micro_prec=precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "micro_prec, macro_prec, weigh_prec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACCURACY\n",
    "\n",
    "y_true = X_train.shape\n",
    "y_pred = X_test.shape\n",
    "accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     bright       1.00      0.84      0.91        87\n",
      "      metal       1.00      0.70      0.82       107\n",
      "       hard       0.94      0.59      0.72        85\n",
      "      rough       1.00      0.61      0.76        95\n",
      "\n",
      "avg / total       0.99      0.68      0.81       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#y_test = clf.predict(y_test) takes it from above\n",
    "y_pred = clf.predict(X_test)\n",
    "categories = ['bright', 'metal', 'hard', 'rough']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
